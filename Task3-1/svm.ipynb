{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK QUESTIONS:\n",
    "# 3.1.2: Which kernel achieved the best accuracy and F1 score?\n",
    "#   Depends on shuffling. see code\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "iris_data = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 7 # Controls shuffling. Same value gives same splitting results\n",
    "tr_data, te_data, tr_target, te_target = train_test_split(iris_data.data, iris_data.target, test_size=0.2, train_size=0.8, random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training  linear accuracy =  0.9666666666666667\n",
      "done training  poly accuracy =  0.9\n",
      "done training  rbf accuracy =  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "kernel_types = [ 'linear', 'poly', 'rbf' ]\n",
    "models = {}\n",
    "\n",
    "# lin, poly, rbf\n",
    "for ktype in kernel_types:\n",
    "    models[ktype] = SVC(kernel=ktype)\n",
    "    models[ktype].fit(tr_data, tr_target)\n",
    "    print(\"done training \", ktype, \"accuracy = \", models[ktype].score(te_data, te_target))\n",
    "\n",
    "# one-vs-one\n",
    "models['ovo'] = None\n",
    "\n",
    "# one-vs-rest\n",
    "models['ovr-linear'] = None\n",
    "models['ovr-poly']   = None\n",
    "models['ovr-rbf']    = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "debug_enable_plots = False\n",
    "\n",
    "def plotConfusionMatrix(kernel):\n",
    "    if not debug_enable_plots: return\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        models[kernel],\n",
    "        te_data,\n",
    "        te_target,\n",
    "        display_labels=iris_data.target_names,\n",
    "        cmap = plt.cm.Blues,\n",
    "        normalize = 'true',\n",
    "    )\n",
    "    disp.ax_.set_title(\"Kernel = \" + kernel)\n",
    "\n",
    "plotConfusionMatrix('linear')\n",
    "plotConfusionMatrix('poly')\n",
    "plotConfusionMatrix('rbf')\n",
    "# one vs one\n",
    "# one vs rest\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear f1: 0.9666666666666667\n",
      "linear acc: 0.9666666666666667\n",
      "poly f1: 0.9\n",
      "poly acc: 0.9\n",
      "rbf f1: 0.8666666666666667\n",
      "rbf acc: 0.8666666666666667\n",
      "===================== Best results\n",
      "f1: (0.9666666666666667, 'linear')\n",
      "acc: (0.9666666666666667, 'linear')\n"
     ]
    }
   ],
   "source": [
    "# F1 + accuracy scores for kernels\n",
    "best_f1 = (0, None)\n",
    "best_acc = (0, None)\n",
    "for k in kernel_types:\n",
    "    preds = models[k].predict(te_data)\n",
    "    f1 = f1_score(te_target, preds, average='micro')\n",
    "    acc = accuracy_score(te_target, preds)\n",
    "    if acc > best_acc[0]: best_acc = (acc, k)\n",
    "    if f1 > best_f1[0]: best_f1 = (f1, k)\n",
    "    print(k + \" f1: \" + str(f1) + \"\\n\" + k + \" acc: \" + str(acc))\n",
    "\n",
    "print(\"===================== Best results\")\n",
    "print(\"f1: \" + str(best_f1) + \"\\nacc: \" + str(best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract support vectors\n",
    "#print(models['one-vs-one'].support_vectors_)\n",
    "#print(models['one-vs-rest'].support_vectors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'feature_names_in'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hanne\\Desktop\\repos\\d7041e-lab1\\Task3-1\\svm.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hanne/Desktop/repos/d7041e-lab1/Task3-1/svm.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Decision boundry\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hanne/Desktop/repos/d7041e-lab1/Task3-1/svm.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(models[\u001b[39m'\u001b[39;49m\u001b[39mlinear\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mfeature_names_in)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'feature_names_in'"
     ]
    }
   ],
   "source": [
    "# Decision boundry\n",
    "print(models['linear'].feature_names_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
