{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK QUESTIONS:\n",
    "# 3.1.2: Which kernel achieved the best accuracy and F1 score?\n",
    "#   Depends on shuffling. see code\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "iris_data = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 7 # Controls shuffling. Same value gives same splitting results\n",
    "tr_data, te_data, tr_target, te_target = train_test_split(iris_data.data, iris_data.target, test_size=0.2, train_size=0.8, random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_types = [ 'linear', 'poly', 'rbf' ]\n",
    "class_types = [ '', 'ovo-', 'ovr-' ]\n",
    "models = {}\n",
    "\n",
    "# lin, poly, rbf\n",
    "for ktype in kernel_types:\n",
    "    models[ktype] = SVC(kernel=ktype)\n",
    "    models[ktype].fit(tr_data, tr_target)\n",
    "\n",
    "# one-vs-one\n",
    "for ktype in kernel_types:\n",
    "    models['ovo-'+ktype] = OneVsOneClassifier(models[ktype])\n",
    "    models['ovo-'+ktype].fit(tr_data, tr_target)\n",
    "\n",
    "# one-vs-rest\n",
    "for ktype in kernel_types:\n",
    "    models['ovr-'+ktype] = OneVsRestClassifier(models[ktype])\n",
    "    models['ovr-'+ktype].fit(tr_data, tr_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "debug_enable_plots = False\n",
    "\n",
    "# '', 'ovo-' (one-vs-one), 'ovr-' (one-vs-rest)\n",
    "model_type = 'ovr-'\n",
    "\n",
    "\n",
    "def plotConfusionMatrix(kernel):\n",
    "    if not debug_enable_plots: return\n",
    "\n",
    "    kernel = model_type + kernel\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        models[kernel],\n",
    "        te_data,\n",
    "        te_target,\n",
    "        display_labels=iris_data.target_names,\n",
    "        cmap = plt.cm.Blues,\n",
    "        normalize = 'true',\n",
    "    )\n",
    "    disp.ax_.set_title(\"Kernel = \" + kernel)\n",
    "\n",
    "plotConfusionMatrix('linear')\n",
    "plotConfusionMatrix('poly')\n",
    "plotConfusionMatrix('rbf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 + accuracy scores for kernels\n",
    "debug_print_steps = False\n",
    "debug_print_results = False\n",
    "\n",
    "best_f1 = (0, None)\n",
    "best_acc = (0, None)\n",
    "for c in class_types:\n",
    "    for k in kernel_types:\n",
    "        k = c + k\n",
    "        preds = models[k].predict(te_data)\n",
    "        f1 = f1_score(te_target, preds, average='micro')\n",
    "        acc = accuracy_score(te_target, preds)\n",
    "        if acc > best_acc[0]: best_acc = (acc, k)\n",
    "        if f1 > best_f1[0]: best_f1 = (f1, k)\n",
    "        if debug_print_steps: print(k + \" f1: \" + str(f1) + \"\\n\" + k + \" acc: \" + str(acc))\n",
    "\n",
    "if debug_print_results: \n",
    "    print(\"===================== Best results\")\n",
    "    print(\"f1: \" + str(best_f1) + \"\\nacc: \" + str(best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract support vectors\n",
    "debug_print_ovr = False\n",
    "\n",
    "def printOvR(kernel):\n",
    "    for e in models['ovr-'+kernel].estimators_:\n",
    "        if debug_print_ovr:\n",
    "            print(\"===============================\")\n",
    "            print(e.support_vectors_)\n",
    "\n",
    "printOvR('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'feature_names_in'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hanne\\Desktop\\repos\\d7041e-lab1\\Task3-1\\svm.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hanne/Desktop/repos/d7041e-lab1/Task3-1/svm.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Decision boundry\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hanne/Desktop/repos/d7041e-lab1/Task3-1/svm.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(models[\u001b[39m'\u001b[39;49m\u001b[39mlinear\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mfeature_names_in)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'feature_names_in'"
     ]
    }
   ],
   "source": [
    "# Decision boundry\n",
    "print(models['linear'].feature_names_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
